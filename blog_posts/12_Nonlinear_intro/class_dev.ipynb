{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# import custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "# demos for this notebook\n",
    "classif_plotter = superlearn.lin_classification_demos\n",
    "optimizers = optlib.optimizers\n",
    "classification_plotter = superlearn.classification_static_plotter.Visualizer();\n",
    "feature_scaling_tools = superlearn.feature_scaling_tools\n",
    "static_plotter = optlib.static_plotter.Visualizer()\n",
    "\n",
    "cost_lib = superlearn.cost_functions\n",
    "\n",
    "# import autograd functionality to bulid function's properly for optimizers\n",
    "import autograd.numpy as np\n",
    "\n",
    "# import timer\n",
    "from datetime import datetime \n",
    "\n",
    "# this is needed to compensate for %matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a class per \n",
    "\n",
    "- input normalization / loading\n",
    "\n",
    "- model\n",
    "\n",
    "- cost function\n",
    "\n",
    "- optimizer\n",
    "\n",
    "- various plotting tools for visualization / debugging\n",
    "\n",
    "Each needs to be made to intake new models we will develop in the chapter to follow.  Lets start with normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class input_normalizer:\n",
    "    '''\n",
    "    A class that wraps up the various input normalization schemes\n",
    "    we have seen including\n",
    "    - mean centering / std normalization\n",
    "    - PCA sphereing\n",
    "    - ZCA sphereing\n",
    "    \n",
    "    For each scheme you put in input features, and the following is returned\n",
    "    - normalizer: the normalization scheme of your choice, returned as a function that \n",
    "    you can then use for future test points\n",
    "    - inverse_normalizer: inverse normalization function for reversing the chosen \n",
    "    normalization\n",
    "    \n",
    "    You can then normalize the input x of a dataset using the desired normalization scheme\n",
    "    by \n",
    "    \n",
    "    x_normalized = normalizer(x)\n",
    "    \n",
    "    and then return the data to its original form as\n",
    "    \n",
    "    x_orig = inverse_normalizer(x_normalized)\n",
    "    '''\n",
    "    \n",
    "    def create_functions(self,x,scheme,**kwargs):\n",
    "        normalizer = 0\n",
    "        inverse_normalizer = 0\n",
    "        \n",
    "        # standard normalization - for each feature subtract mean, divide by standard deviation \n",
    "        if scheme == 'standard':\n",
    "            normalizer, inverse_normalizer = self.standard(x)\n",
    "        \n",
    "        # PCA-sphereing - use PCA to normailze input features\n",
    "        if scheme =='PCA-sphereing':\n",
    "            normalizer, inverse_normalizer = self.PCA_sphere(x,**kwargs)\n",
    "        \n",
    "        return normalizer, inverse_normalizer\n",
    "\n",
    "    # standard normalizer - subtract mean, divide by standard deviation - for each input feature\n",
    "    def standard(self,x):\n",
    "        # compute mean / std of each input feature\n",
    "        x_means = np.mean(x,axis = 1)[:,np.newaxis]\n",
    "        x_stds = np.std(x,axis = 1)[:,np.newaxis]    \n",
    "\n",
    "        # create normalizer and input normalizer functions based on mean / std\n",
    "        normalizer = lambda data: (data - x_means)/x_stds\n",
    "        \n",
    "        # create inverse normalizer function \n",
    "        inverse_normalizer = lambda data: data*x_stds + x_means\n",
    "        \n",
    "        return normalizer, inverse_normalizer\n",
    "        \n",
    "    ##### PCA-sphereing functions ####\n",
    "    # PCA-sphereing - use PCA to normalize input features\n",
    "    def PCA_sphere(self,x,**kwargs):\n",
    "        # standard normalize the input data\n",
    "        standard_normalizer, inv_standard_normalizer = self.standard(x)\n",
    "        \n",
    "        # compute pca transform and inverse transform for sphereing\n",
    "        D,V = self.PCA(x_standard,**kwargs)\n",
    "        D1 = np.array([d**(0.5) for d in D])\n",
    "        D2 = np.array([1/d**(0.5) for d in D])\n",
    "        D1_full = np.diag(D1)\n",
    "        D2_full = np.diag(D2)\n",
    "        M = np.dot(D2_full,V.T)\n",
    "        M_inv = np.dot(V,D1_full)\n",
    "        \n",
    "        # make normalizer and inverse normalizer\n",
    "        normalizer = lambda data: np.dot(M,standard_normalizer(data))\n",
    "        inverse_normalizer = lambda data: np.dot(M_inv,inv_standard_normalizer(data))\n",
    "\n",
    "        return normalizer, inverse_normalizer\n",
    "    \n",
    "    # compute eigendecomposition of data covariance matrix\n",
    "    def PCA(self,x,**kwargs):\n",
    "        '''\n",
    "        A function for producing the full PCA transformation on an input dataset.  \n",
    "        '''\n",
    "        lam = 10**(-7)\n",
    "        if 'lam' in kwargs:\n",
    "            lam = kwargs['lam']\n",
    "            \n",
    "        # create the correlation matrix\n",
    "        P = float(x.shape[1])\n",
    "        Cov = 1/P*np.dot(x,x.T) + lam*np.eye(x.shape[0])\n",
    "\n",
    "        # use numpy function to compute eigenvalues / vectors of correlation matrix\n",
    "        D,V = np.linalg.eigh(Cov)\n",
    "        return D,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "data = np.loadtxt(datapath + '2d_classification_data_v1.csv')\n",
    "\n",
    "# get input/output pairs\n",
    "x = data[:,:-1:].T\n",
    "y = data[:,-1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalization test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "data = np.loadtxt(datapath + 'breast_cancer_data.csv',delimiter = ',')\n",
    "\n",
    "# get input/output pairs\n",
    "x = data[:,:-1:].T\n",
    "y = data[:,-1:] \n",
    "\n",
    "# normalize input\n",
    "a = input_normalizer()\n",
    "scheme = 'standard'\n",
    "normalizer, inverse_normalizer = a.create_functions(x,scheme)\n",
    "x_normalized = normalizer(x)\n",
    "\n",
    "# tack a 1 onto the top of each input point\n",
    "o = np.ones((1,np.shape(x_orig)[1]));\n",
    "x = np.concatenate((o,x_orig),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully evaluate our network features using the tensor of weights in omega_inner\n",
    "def compute_features(x, omega_inner):\n",
    "    o = np.ones((np.shape(x)[0],1))\n",
    "    a_padded = np.concatenate((o,x),axis = 1)\n",
    "    \n",
    "    # loop through each layer matrix\n",
    "    for W in omega_inner:\n",
    "        # output of layer activation\n",
    "        a = activation(np.dot(a_padded,W))\n",
    "                \n",
    "        #  pad with ones (to compactly take care of bias) for next layer computation\n",
    "        o = np.ones((np.shape(a)[0],1))\n",
    "        a_padded = np.concatenate((o,a),axis = 1)\n",
    "        \n",
    "    return a_padded\n",
    "\n",
    "# our predict function \n",
    "def predict(x,omega):     \n",
    "    # compute network features - here omega[0] contains the entire tensor of internal weights\n",
    "    f = compute_features(x,omega[0])\n",
    "    \n",
    "    # compute linear model compactly via inner product - here omega[1] contains only those weights in the final linear combination of network features\n",
    "    vals = np.dot(f,omega[1])\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
