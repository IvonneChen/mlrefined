{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# import custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "# demos for this notebook\n",
    "classif_plotter = superlearn.lin_classification_demos\n",
    "optimizers = optlib.optimizers\n",
    "classification_plotter = superlearn.classification_static_plotter.Visualizer();\n",
    "feature_scaling_tools = superlearn.feature_scaling_tools\n",
    "static_plotter = optlib.static_plotter.Visualizer()\n",
    "from mlrefined_libraries import unsupervised_library as unsuplib\n",
    "\n",
    "\n",
    "cost_lib = superlearn.cost_functions\n",
    "\n",
    "# import autograd functionality to bulid function's properly for optimizers\n",
    "import autograd.numpy as np\n",
    "\n",
    "# import timer\n",
    "from datetime import datetime \n",
    "\n",
    "# this is needed to compensate for %matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a class per \n",
    "\n",
    "- input normalization / loading\n",
    "\n",
    "- model\n",
    "\n",
    "- cost function\n",
    "\n",
    "- optimizer\n",
    "\n",
    "- various plotting tools for visualization / debugging\n",
    "\n",
    "Each needs to be made to intake new models we will develop in the chapter to follow.  Lets start with normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class input_normalizer:\n",
    "    '''\n",
    "    A class that wraps up the various input normalization schemes\n",
    "    we have seen including\n",
    "    - mean centering / std normalization\n",
    "    - PCA sphereing\n",
    "    - ZCA sphereing\n",
    "    \n",
    "    For each scheme you put in input features, and the following is returned\n",
    "    - normalizer: the normalization scheme of your choice, returned as a function that \n",
    "    you can then use for future test points\n",
    "    - inverse_normalizer: inverse normalization function for reversing the chosen \n",
    "    normalization\n",
    "    \n",
    "    You can then normalize the input x of a dataset using the desired normalization scheme\n",
    "    by \n",
    "    \n",
    "    x_normalized = normalizer(x)\n",
    "    \n",
    "    and then return the data to its original form as\n",
    "    \n",
    "    x_orig = inverse_normalizer(x_normalized)\n",
    "    '''\n",
    "    \n",
    "    def create_functions(self,x,scheme,**kwargs):\n",
    "        normalizer = 0\n",
    "        inverse_normalizer = 0\n",
    "        \n",
    "        # standard normalization - for each feature subtract mean, divide by standard deviation \n",
    "        if scheme == 'standard':\n",
    "            normalizer, inverse_normalizer = self.standard(x)\n",
    "        \n",
    "        # PCA-sphereing - use PCA to normailze input features\n",
    "        if scheme =='PCA-sphereing':\n",
    "            normalizer, inverse_normalizer = self.PCA_sphere(x,**kwargs)\n",
    "        \n",
    "        return normalizer, inverse_normalizer\n",
    "\n",
    "    # standard normalizer - subtract mean, divide by standard deviation - for each input feature\n",
    "    def standard_normalizer(self,x):\n",
    "        # compute mean / std of each input feature\n",
    "        x_means = np.mean(x,axis = 1)[:,np.newaxis]\n",
    "        x_stds = np.std(x,axis = 1)[:,np.newaxis]    \n",
    "\n",
    "        # create normalizer and input normalizer functions based on mean / std\n",
    "        normalizer = lambda data: (data - x_means)/x_stds\n",
    "        \n",
    "        # create inverse normalizer function \n",
    "        inverse_normalizer = lambda data: data*x_stds + x_means\n",
    "        \n",
    "        return normalizer, inverse_normalizer\n",
    "        \n",
    "    ##### PCA-sphereing functions ####\n",
    "    # PCA-sphereing - use PCA to normalize input features\n",
    "    def PCA_sphereing(self,x,**kwargs):\n",
    "        # standard normalize the input data\n",
    "        standard_normalizer, inv_standard_normalizer = self.standard(x)\n",
    "        x_standard = standard_normalizer(x)\n",
    "        \n",
    "        # compute pca transform and inverse transform for sphereing\n",
    "        D,V = self.PCA(x_standard,**kwargs)\n",
    "        D1 = np.array([d**(0.5) for d in D])\n",
    "        D2 = np.array([1/d**(0.5) for d in D])\n",
    "        D1_full = np.diag(D1)\n",
    "        D2_full = np.diag(D2)\n",
    "        M = np.dot(D2_full,V.T)\n",
    "        M_inv = np.dot(V,D1_full)\n",
    "        \n",
    "        # make normalizer and inverse normalizer\n",
    "        normalizer = lambda data: np.dot(M,standard_normalizer(data))\n",
    "        inverse_normalizer = lambda data: np.dot(M_inv,inv_standard_normalizer(data))\n",
    "\n",
    "        return normalizer, inverse_normalizer\n",
    "    \n",
    "    # compute eigendecomposition of data covariance matrix\n",
    "    def PCA(self,x,**kwargs):\n",
    "        '''\n",
    "        A function for producing the full PCA transformation on an input dataset.  \n",
    "        '''\n",
    "        lam = 10**(-7)\n",
    "        if 'lam' in kwargs:\n",
    "            lam = kwargs['lam']\n",
    "\n",
    "        # create the correlation matrix\n",
    "        P = float(x.shape[1])\n",
    "        Cov = 1/P*np.dot(x,x.T) + lam*np.eye(x.shape[0])\n",
    "\n",
    "        # use numpy function to compute eigenvalues / vectors of correlation matrix\n",
    "        D,V = np.linalg.eigh(Cov)\n",
    "        return D,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = input_normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in dataset to perform PCA on\n",
    "X_original = np.loadtxt(datapath + '2d_span_data.csv',delimiter=',')\n",
    "\n",
    "# mean-center the data\n",
    "x_sphered\n",
    "\n",
    "# compute the full PCA transformation of dataset\n",
    "W,S = PCA_sphere(X)\n",
    "\n",
    "# compute principal components\n",
    "unsuplib.PCA_demos.sphereing_visualizer(X,W,S,pcs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
